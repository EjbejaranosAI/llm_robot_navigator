# LLM Robot Navigation

**ðŸš§ EN DEVELOPMENT ðŸš§**

## Overview

This project aims to develop a robot navigation system guided by a Large Language Model (LLM). The application allows users to upload or provide an image, which is then analyzed by the LLM to understand the environment. Based on the analysis, the system builds a navigation graph, suggesting potential actions and paths. The ultimate goal is to enable a robot to autonomously navigate through an environment based on high-level instructions and visual input.

## Current Features

- **Image Input:** Users can provide images by uploading a file (JPG, JPEG, PNG) or by entering an image URL.
- **LLM-Powered Image Analysis:** Utilizes an LLM (currently based on OpenAI's GPT models) to:
  - Provide an overall scene description.
  - Identify objects.
  - Detect potential navigation paths.
  - Identify obstacles.
  - Recognize landmarks and suggest a node name.
  - Understand the robot's perspective and propose potential actions.
- **Navigation Graph Building:** Uses the `networkx` library to construct a directed graph:
  - **Nodes:** Represent locations or significant points, storing scene descriptions, associated images, and raw JSON responses from the LLM.
  - **Edges:** Represent actions taken between nodes (e.g., "walk through the door", "turn left") as labels.
- **Graph Visualization:** Displays the navigation graph with `streamlit-agraph` for clear visual connections.
- **Node Information Display:** Clickable nodes show detailed information including the captured image, textual description, and raw JSON response.
- **Navigation Goal Setting:** Allows users to input a navigation goal for future path planning.
- **Action History:** Tracks the actions taken during a navigation session.
- **Start New Navigation:** A reset button to clear the current session (graph and state).
- **History of Analyzed Images:** Displays a preview of analyzed images for session review.

## Project Structure
```
llm_robot_navigator/              <-- Directorio RaÃ­z del Proyecto
â”œâ”€â”€ .env                          <-- Archivo para claves API (Â¡NO SUBIR A GIT!)
â”œâ”€â”€ .gitignore                    <-- Archivo para ignorar archivos/directorios en Git
â”œâ”€â”€ requirements.txt              <-- Lista de dependencias Python (pip freeze > requirements.txt)
â”œâ”€â”€ README.md                     <-- DescripciÃ³n del proyecto, instrucciones de setup, etc.
â”‚
â”œâ”€â”€ src/                          <-- Directorio principal del cÃ³digo fuente Python
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/                      <-- MÃ³dulos relacionados con APIs externas (OpenAI)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ gpt_client.py
â”‚   â”œâ”€â”€ mapping/                  <-- LÃ³gica para crear y manejar el grafo/mapa
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ graph_manager.py
â”‚   â”œâ”€â”€ navigation/               <-- LÃ³gica de planificaciÃ³n de rutas y replanificaciÃ³n
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ planner.py
â”‚   â”œâ”€â”€ interfaces/               <-- CÃ³digo para interfaces de usuario (Streamlit)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ streamlit_app.py      <-- Tu aplicaciÃ³n Streamlit principal
â”‚   â”œâ”€â”€ utils/                    <-- Funciones de utilidad compartidas (manejo de imÃ¡genes, etc.)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ prompts.py
â”‚   â””â”€â”€ main.py                   <-- Punto de entrada principal (si no es la app Streamlit)
â”‚
â”œâ”€â”€ ros_ws/                       <-- ROS Workspace (para la Fase 2)
â”‚   â”œâ”€â”€ src/                      <-- Directorio 'src' del workspace de ROS
â”‚   â”‚   â”œâ”€â”€ llm_robot_pkg/        <-- Tu paquete ROS personalizado
â”‚   â”‚   â”‚   â”œâ”€â”€ package.xml
â”‚   â”‚   â”‚   â”œâ”€â”€ setup.py          <-- (Para ROS 2 Python)
â”‚   â”‚   â”‚   â”œâ”€â”€ CMakeLists.txt    <-- (Si usas C++ o mixto)
â”‚   â”‚   â”‚   â”œâ”€â”€ launch/           <-- Archivos de lanzamiento ROS
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ navigation_sim.launch.py
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes/            <-- Scripts ejecutables (nodos ROS)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm_service_node.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ graph_manager_node.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ planner_node.py
â”‚   â”‚   â”‚   â””â”€â”€ llm_robot_pkg/    <-- CÃ³digo Python del paquete (ROS 2)
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ llm_service.py
â”‚   â”‚   â”‚       â”œâ”€â”€ graph_node.py
â”‚   â”‚   â”‚       â””â”€â”€ planner_logic.py
â”‚   â”‚   â””â”€â”€ ... (otros paquetes si los usas)
â”‚
â”œâ”€â”€ simulation/                   <-- Archivos de configuraciÃ³n de la simulaciÃ³n
â”‚   â”œâ”€â”€ worlds/                   <-- Archivos de mundo Gazebo (.world)
â”‚   â”œâ”€â”€ models/                   <-- Modelos de robot/objetos (.sdf, .urdf)
â”‚   â””â”€â”€ config/                   <-- Archivos de configuraciÃ³n (Nav2 params, RViz config)
â”‚
â”œâ”€â”€ data/                         <-- Datos generados o necesarios (mapas guardados, logs - Â¡cuidado con el tamaÃ±o en Git!)
â”‚   â””â”€â”€ graphs/                   <-- Grafos guardados
â”‚
â”œâ”€â”€ notebooks/                    <-- Jupyter notebooks para experimentaciÃ³n y anÃ¡lisis
â”‚   â””â”€â”€ 01_test_gpt_vision.ipynb
â”‚
â””â”€â”€ tests/                        <-- Pruebas unitarias e de integraciÃ³n
    â”œâ”€â”€ test_api.py
    â””â”€â”€ test_mapping.py
```



## Project TODO: LLM Robot Navigation

### Phase 0: Setup ðŸ› ï¸
- [x] **Define:** Project goals & success metrics. ðŸŽ¯
- [x] **Select:** Tech stack (Python ðŸ, LLM ðŸ—£ï¸, Streamlit ðŸ“Š, ROS ðŸ¤–, Simulation âš™ï¸).
- [x] **Setup:** Development environment & Git ðŸŒ³.
- [x] **Configure:** Secure OpenAI API access ðŸ”‘.

### Phase 1: Core Logic & Web Interface ðŸ’»
- [x] **Connect:** Implement GPT API connection function. ðŸ”—
- [x] **Describe:** Code function to get image descriptions via API. ðŸ–¼ï¸ðŸ“
- [x] **Build UI:** Create basic Streamlit app (image upload/view). ðŸ—ï¸ðŸ“Š
- [x] **Test:** Verify image description quality. âœ…ðŸ§ª
- [x] **Design Graph:** Define node/edge structure for the navigation graph. ðŸ—ºï¸âœï¸
- [x] **Build Graph:** Create graph-building functionality using `networkx`. âš™ï¸ðŸŒ³
- [x] **Visualize Graph:** Display navigation graph with `streamlit-agraph`. ðŸ‘ï¸ðŸ“Š

### Phase 2: ROS Integration & Simulation ðŸ¤–
- [ ] **Setup ROS Workspace:** Create ROS workspace and necessary packages. ðŸ”§
- [ ] **ROS Node 1:** Develop `llm_service_node.py` to interface with GPT and image analysis. ðŸ§ 
- [ ] **ROS Node 2:** Create `graph_manager_node.py` to manage the navigation graph. ðŸ“
- [ ] **ROS Node 3:** Implement `planner_node.py` for path planning and action execution. ðŸ›£ï¸
- [ ] **Integrate with Simulation:** Test integration with simulation tools (Gazebo, RViz). ðŸš—

## Getting Started ðŸš€

### Prerequisites
- Python 3.x ðŸ
- pip (Python package installer)
- An OpenAI API key ðŸ”‘

### Installation â¬‡ï¸
1. Clone the repository to your local machine.
2. Navigate to the project's root directory.
3. Install the required Python dependencies:
   ```bash
   pip install -r requirements.txt
